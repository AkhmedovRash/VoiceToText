!pip -q install SpeechRecognition jiwer ffmpeg-python

import os, io, base64
import ffmpeg
import speech_recognition as sr
from jiwer import wer
from scipy.io.wavfile import read as wav_read
from IPython.display import HTML, Audio, display

AUDIO_HTML = """
<script>
let rec, gum, dataPromise;
const btn = document.createElement("button");
btn.textContent = "Start recording";
document.body.appendChild(btn);

function sleep(ms){ return new Promise(r=>setTimeout(r,ms)); }

btn.onclick = async () => {
  if (!rec || rec.state === "inactive") {
    const stream = await navigator.mediaDevices.getUserMedia({audio:true});
    gum = stream;
    rec = new MediaRecorder(stream);
    const chunks = [];
    rec.ondataavailable = e => chunks.push(e.data);
    rec.onstop = async () => {
      const blob = new Blob(chunks, {type: "audio/webm;codecs=opus"});
      const reader = new FileReader();
      reader.onloadend = () => {
        const b64 = reader.result;
        google.colab.kernel.invokeFunction('notebook.getAudio', [b64], {});
      };
      reader.readAsDataURL(blob);
    };
    rec.start();
    btn.textContent = "Recording... click to stop";
  } else {
    rec.stop();
    gum.getTracks().forEach(t=>t.stop());
    btn.textContent = "Saving...";
    await sleep(500);
    btn.textContent = "Start recording";
  }
};
</script>
"""

from google.colab import output
received_b64 = {"data": None}

def _receive_audio(b64):
    received_b64["data"] = b64

output.register_callback('notebook.getAudio', _receive_audio)

def record_to_wav(out_path="recording.wav"):
    # Render the JS UI and wait for user to click (record -> stop)
    display(HTML(AUDIO_HTML))
    print("Click the button: start recording, then click again to stop...")
    # Wait until JS sets the base64 payload
    while received_b64["data"] is None:
        pass
    b64 = received_b64["data"]
    received_b64["data"] = None  # reset
    # Strip header 'data:audio/webm;codecs=opus;base64,'
    raw = base64.b64decode(b64.split(',', 1)[1])
    # Convert WebM/Opus -> WAV (PCM) via ffmpeg
    process = (
        ffmpeg
        .input('pipe:0')
        .output(out_path, format='wav', acodec='pcm_s16le', ac=1, ar='16000')
        .overwrite_output()
        .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True)
    )
    stdout, stderr = process.communicate(input=raw)
    return out_path

def recognize_wav(path, language="ru-RU", duration=None, offset=None):
    r = sr.Recognizer()
    with sr.AudioFile(path) as source:
        audio = r.record(source, duration=duration, offset=offset)
    return r.recognize_google(audio, language=language)

target_phrase = "раз два три огонь вода снег солнце"  # your reference string

wav_path = record_to_wav("recording.wav")
display(Audio(wav_path, rate=16000))

try:
    hyp = recognize_wav(wav_path, language="ru-RU")
    print("Оригинал:               ", target_phrase)
    print("Результат распознавания:", hyp)
    print("WER:", wer(target_phrase.lower(), hyp.lower()))
except sr.UnknownValueError:
    print("Распознать не удалось (нет речи или низкое качество).")
except sr.RequestError as e:
    print("Ошибка запроса к Google Speech Recognition:", e)
