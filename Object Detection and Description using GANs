'''
This code is an implementation of a Generative Adversarial Network (GAN) based model for detecting objects and generating their descriptions based on the COCO dataset.

The main steps in the code include:

Loading the necessary libraries and modules.
Loading and pre-processing COCO set data for the selected category of objects (for example, "dogs").
Loading object detection model and descriptions from pretrained weights.
Preparing data for training a GAN model, including loading images, annotations, and embedded vector representations (embeddings).
Building and training a generator (stage1_generator) and discriminator (stage1_discriminator) model based on the GAN architecture.
Create and train an adversarial model (adversarial_model) that combines a generator and a discriminator to train the generator to create realistic images and descriptions of objects.
Generation of new images and descriptions using the trained GAN model.
Additional features in the code include loading classes, embeddings, and filenames, as well as handling images and object bounding box data.

Note: The described code is only a fragment and does not contain a complete implementation of all functions and details. 
'''
import os
import pickle
import random
import time
import PIL
import numpy as np
import pandas as pd
import tensorflow as tf

from PIL import Image
from tensorflow.keras import Input, Model
from tensorflow.keras import backend as K
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.layers import Dense, LeakyReLU, BatchNormalization, ReLU, Reshape, UpSampling2D, Conv2D, Activation, Conv2DTranspose,concatenate, Flatten, Lambda, Concatenate
from tensorflow.keras.optimizers import Adam
from matplotlib import pyplot as plt
from pycocotools.coco import COCO

import numpy as np
from urllib.request import urlretrieve
import os
from google.colab import files
import shutil 
from socket import error as SocketError
import errno
import pandas as pd
import json
from tqdm.notebook import tqdm

# Object detection + description
def load_class(cat_name, prefix = 'train2017', annotation_folder='/content/annotations', download=False):
    instances = annotation_folder+'/instances_{}.json'.format(prefix)
    coco = COCO(instances)

    captions = annotation_folder+'/captions_{}.json'.format(prefix)
    coco_txt = COCO(captions)

    cats = coco.loadCats(coco.getCatIds())
    nms=[cat['name'] for cat in cats]
    print('COCO categories: \n{}\n'.format(', '.join(nms))) 
    print('-'*40)

    category_ids = coco.getCatIds([cat_name]) 
    image_ids2   = coco.getImgIds(catIds=category_ids) 

    os.makedirs('/content/data/cat', exist_ok=True) 
    os.makedirs('/content/data/cat_ann', exist_ok=True)

    print('Selected category - ', cat_name, end='\n\n')
    for i in tqdm(image_ids2, desc='Downloading images'): 
      try:
        image_data = coco.loadImgs(i)[0] 
        urlretrieve(image_data['coco_url'], '/content/data/cat/{}' .format(image_data['file_name'])) 
      except SocketError as e: 
        if e.errno != errno.ECONNRESET:
          raise 
        pass 

    ann_ids = coco.getAnnIds(catIds=category_ids) 
    all_ann = coco.loadAnns(ann_ids)

    df_rows = []

    for i in tqdm(range(0, len(all_ann)), desc='Downloading bboxes'): 
        cur_ann    = all_ann[i]
        cbbox      = cur_ann["bbox"]
        cimg_info  = coco.loadImgs(cur_ann["image_id"])

        if(len(cimg_info) > 1):
            print("ERROR: More than one image got loaded")
            sys.exit(1)
                                            
        filename = cimg_info[0]["file_name"] 
        idx      = cimg_info[0]["id"]        
        cur_class= cat_name
        width    = cimg_info[0]["width"]     
        height   = cimg_info[0]["height"]    
        xmin     = int(cbbox[0])            
        ymin     = int(cbbox[1])             
        xmax     = min(int(xmin + cbbox[2]), width-1) 
        ymax     = min(int(ymin + cbbox[3]), height-1)
        df_rows  = df_rows + [[filename, idx, str(width), str(height), cur_class,
                              str(xmin), str(ymin), str(xmax), str(ymax)]] 
    df=pd.DataFrame(df_rows, columns=["filename", "idx", "width", "height", "class",
                              "xmin", "ymin", "xmax", "ymax"]) 
    print('Не скачалось файлов из-за ошибок: ', df.filename.nunique() - len(os.listdir('/content/data/cat')))

    with open(captions, 'r') as f:
        annotations = json.load(f) 
    df_rows_txt = []
    for i, annot in enumerate(annotations['annotations']): 
      if annot['image_id'] in image_ids2:
        df_rows_txt = df_rows_txt + [[annot['image_id'], annot['caption']]] 
                                    
    df_txt = pd.DataFrame(df_rows_txt, columns=["idx", "description"]) 
    df_filter = df['filename'].isin(os.listdir('/content/data/cat'))
    data_BB = df[df_filter]
    data_BB.to_csv('/content/data/cat_ann/ann_BB_{}.csv' .format(prefix))
    print('После маски, число скачанных файлов = числу описаний в csv:', data_BB.filename.nunique() == len(os.listdir('/content/data/cat')))
    df_filter = df_txt['idx'].isin(data_BB['idx'])
    data_txt = df_txt[df_filter]
    data_txt.to_csv('/content/data/cat_ann/ann_description_{}.csv' .format(prefix))
    data_concat = data_txt.merge(data_BB, on='idx')
    data_concat.to_csv('/content/data/cat_ann/ann_description+BB_{}.csv' .format(prefix))

    shutil.make_archive('img_{}' .format(prefix), 'zip', '/content/data/cat/')

    if download: 
      files.download('/content/img_{}.zip' .format(prefix))
      files.download('/content/data/cat_ann/ann_BB_{}.csv' .format(prefix))
      files.download('/content/data/cat_ann/ann_description_{}.csv' .format(prefix))
      files.download('/content/data/cat_ann/ann_description+BB_{}.csv' .format(prefix))

    print('Всего скачали изображений конкретного класса: ', len(os.listdir('/content/data/cat'))) 
!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip
!unzip annotations_trainval2017.zip
load_class('dog', 'val2017')
annotations = pd.read_csv('/content/data/cat_ann/ann_description+BB_val2017.csv')
annotations[annotations['idx'] == 395801]
from google.colab import drive
drive.mount('/content/drive')
!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip #скачиваем датасет COCO
!unzip annotations_trainval2017.zipn
load_class('dog', 'val2017')
annotations = pd.read_csv('/content/data/cat_ann/ann_description+BB_val2017.csv')
annotations[annotations['idx'] == 395801]
def load_class_ids(class_info_file_path): 
    with open(class_info_file_path, 'rb') as f:
        class_ids = pickle.load(f, encoding='latin1')
        return class_ids   
def load_embeddings(embeddings_file_path): 
    with open(embeddings_file_path, 'rb') as f:
        embeddings = pickle.load(f, encoding='latin1')
        embeddings = np.array(embeddings)
        print('embeddings: ', embeddings.shape)
    return embeddings
def load_filenames(filenames_file_path): 
    with open(filenames_file_path, 'rb') as f:
        filenames = pickle.load(f, encoding='latin1')
    return filenames
def load_bounding_boxes(dataset_dir): 
    bounding_boxes_path = os.path.join(dataset_dir, 'bounding_boxes.txt')
    file_paths_path = os.path.join(dataset_dir, 'images.txt')
    df_bounding_boxes = pd.read_csv(bounding_boxes_path,
                                    delim_whitespace=True, header=None).astype(int)
    df_file_names = pd.read_csv(file_paths_path, delim_whitespace=True, header=None)
    file_names = df_file_names[1].tolist()
    filename_boundingbox_dict = {img_file[:-4]: [] for img_file in file_names[:2]}
    for i in range(0, len(file_names)):
        bounding_box = df_bounding_boxes.iloc[i][1:].tolist()
        key = file_names[i][:-4]
        filename_boundingbox_dict[key] = bounding_box
    return filename_boundingbox_dict
def get_img(img_path, bbox, image_size):
    img = Image.open(img_path).convert('RGB')
    width, height = img.size
    if bbox is not None:
        R = int(np.maximum(bbox[2], bbox[3]) * 0.75)
        center_x = int((2 * bbox[0] + bbox[2]) / 2)
        center_y = int((2 * bbox[1] + bbox[3]) / 2)
        y1 = np.maximum(0, center_y - R)
        y2 = np.minimum(height, center_y + R)
        x1 = np.maximum(0, center_x - R)
        x2 = np.minimum(width, center_x + R)
        img = img.crop([x1, y1, x2, y2])
    img = img.resize(image_size, PIL.Image.BILINEAR)
    return img
def load_dataset(filenames_file_path, class_info_file_path, cub_dataset_dir, embeddings_file_path, image_size):
    filenames = load_filenames(filenames_file_path)
    class_ids = load_class_ids(class_info_file_path)
    bounding_boxes = load_bounding_boxes(cub_dataset_dir)
    all_embeddings = load_embeddings(embeddings_file_path)
    X, y, embeddings = [], [], []
    print("Embeddings shape:", all_embeddings.shape)
    for index, filename in enumerate(filenames):
        bounding_box = bounding_boxes[filename]
        try:
            img_name = '{}/images/{}.jpg'.format(cub_dataset_dir, filename)
            img = get_img(img_name, bounding_box, image_size)

            all_embeddings1 = all_embeddings[index, :, :]

            embedding_ix = random.randint(0, all_embeddings1.shape[0] - 1)
            embedding = all_embeddings1[embedding_ix, :]

            X.append(np.array(img))
            y.append(class_ids[index])
            embeddings.append(embedding)
        except Exception as e:
            print(e)

    X = np.array(X)
    y = np.array(y)
    embeddings = np.array(embeddings)
    return X, y, embeddings
def generate_c(x): 
    mean = x[:, :128]
    log_sigma = x[:, 128:]
    stddev = K.exp(log_sigma)
    epsilon = K.random_normal(shape=K.constant((mean.shape[1],), dtype='int32'))
    c = stddev * epsilon + mean
    return c
def build_embedding_compressor_model(): 
    input_layer = Input(shape=(1024,))
    x = Dense(128)(input_layer)
    x = ReLU()(x)

    model = Model(inputs=[input_layer], outputs=[x])
    return model
  
def build_stage1_generator(): #генератор на стадии 1
    input_layer = Input(shape=(1024,))
    x = Dense(256)(input_layer)
    mean_logsigma = LeakyReLU(alpha=0.2)(x)

    c = Lambda(generate_c)(mean_logsigma)

    input_layer2 = Input(shape=(100,))

    gen_input = Concatenate(axis=1)([c, input_layer2])

    x = Dense(128 * 8 * 4 * 4, use_bias=False)(gen_input)
    x = ReLU()(x)

    x = Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)

    x = Conv2DTranspose(512, kernel_size=3, padding="same", strides=1, use_bias=False)(x)
    x = Conv2D(512, kernel_size=3, padding="same", strides=1, use_bias=False)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)

    x = Conv2DTranspose(2, kernel_size=3, padding="same", strides=4, use_bias=False)(x)
    x = Conv2D(512, kernel_size=3, padding="same", strides=1, use_bias=False)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)

    x = Conv2DTranspose(2, kernel_size=3, padding="same", strides=4, use_bias=False)(x)
    x = Conv2D(128, kernel_size=3, padding="same", strides=4, use_bias=False)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)

    x = Conv2DTranspose(2, kernel_size=3, padding="same", strides=4, use_bias=False)(x)
    x = Conv2D(64, kernel_size=3, padding="same", strides=1, use_bias=False)(x)
    x = BatchNormalization()(x)
    x = ReLU()(x)

    x = Conv2D(3, kernel_size=3, padding="same", strides=1, use_bias=False)(x)
    x = Activation(activation='tanh')(x)

    stage1_gen = Model(inputs=[input_layer, input_layer2], outputs=[x, mean_logsigma])
    return stage1_gen

def build_stage1_discriminator(): 
    input_layer = Input(shape=(64, 64, 3))

    x = Conv2D(64, (4, 4),
               padding='same', strides=2,
               input_shape=(64, 64, 3), use_bias=False)(input_layer)
    x = LeakyReLU(alpha=0.2)(x)

    x = Conv2D(128, (4, 4), padding='same', strides=2, use_bias=False)(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = Conv2D(256, (4, 4), padding='same', strides=2, use_bias=False)(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = Conv2D(512, (4, 4), padding='same', strides=2, use_bias=False)(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)

    input_layer2 = Input(shape=(4, 4, 128))

    merged_input = concatenate([x, input_layer2])

    x2 = Conv2D(64 * 8, kernel_size=1,
                padding="same", strides=1)(merged_input)
    x2 = BatchNormalization()(x2)
    x2 = LeakyReLU(alpha=0.2)(x2)
    x2 = Flatten()(x2)
    x2 = Dense(1)(x2)
    x2 = Activation('sigmoid')(x2)

    stage1_dis = Model(inputs=[input_layer, input_layer2], outputs=[x2])
    return stage1_dis
  
def build_adversarial_model(gen_model, dis_model): 
    input_layer = Input(shape=(1024,))
    input_layer2 = Input(shape=(100,))
    input_layer3 = Input(shape=(4, 4, 128))

    x, mean_logsigma = gen_model([input_layer, input_layer2])

    dis_model.trainable = False
    valid = dis_model([x, input_layer3])

    model = Model(inputs=[input_layer, input_layer2, input_layer3], outputs=[valid, mean_logsigma])
    return model
def KL_loss(y_true, y_pred): 
    mean = y_pred[:, :128]
    logsigma = y_pred[:, :128]
    loss = -logsigma + .5 * (-1 + K.exp(2. * logsigma) + K.square(mean))
    loss = K.mean(loss)
    return loss
def custom_generator_loss(y_true, y_pred):
    return K.binary_crossentropy(y_true, y_pred)
def save_rgb_img(img, path): 
    fig = plt.figure()
    ax = fig.add_subplot(1, 1, 1)
    ax.imshow(img)
    ax.axis("off")
    ax.set_title("Image")
    plt.savefig(path)
    plt.close()
data_dir = "/content/birds/"
train_dir = data_dir + "/train"
test_dir = data_dir + "/test"
image_size = 64
batch_size = 64
z_dim = 100
stage1_generator_lr = 0.0002
stage1_discriminator_lr = 0.0002
stage1_lr_decay_step = 600
epochs = 1000
condition_dim = 128
embeddings_file_path_train = train_dir + "/char-CNN-RNN-embeddings.pickle"
embeddings_file_path_test = test_dir + "/char-CNN-RNN-embeddings.pickle"
filenames_file_path_train = train_dir + "/filenames.pickle"
filenames_file_path_test = test_dir + "/filenames.pickle"
class_info_file_path_train = train_dir + "/class_info.pickle"
class_info_file_path_test = test_dir + "/class_info.pickle"
cub_dataset_dir =  "/content/CUB_200_2011"
dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)
gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)
X_train, y_train, embeddings_train = load_dataset(filenames_file_path=filenames_file_path_train,
                                                  class_info_file_path=class_info_file_path_train,
                                                  cub_dataset_dir=cub_dataset_dir,
                                                  embeddings_file_path=embeddings_file_path_train,
                                                  image_size=(64, 64))

X_test, y_test, embeddings_test = load_dataset(filenames_file_path=filenames_file_path_test,
                                                class_info_file_path=class_info_file_path_test,
                                                cub_dataset_dir=cub_dataset_dir,
                                                embeddings_file_path=embeddings_file_path_test,
                                                image_size=(64, 64))

stage1_dis = build_stage1_discriminator()
stage1_dis.compile(loss='binary_crossentropy', optimizer=dis_optimizer)

stage1_gen = build_stage1_generator()
stage1_gen.compile(loss="mse", optimizer=gen_optimizer)

embedding_compressor_model = build_embedding_compressor_model()
embedding_compressor_model.compile(loss="binary_crossentropy", optimizer="adam")

adversarial_model = build_adversarial_model(gen_model=stage1_gen, dis_model=stage1_dis)
adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1, 2.0],
                          optimizer=gen_optimizer, metrics=None)
real_labels = np.ones((batch_size, 1), dtype=float) * 0.9
fake_labels = np.zeros((batch_size, 1), dtype=float) + 0.1
for epoch in range(epochs):
    print("========================================")
    print("Epoch is:", epoch)
    print("Number of batches", int(X_train.shape[0] / batch_size))
    gen_losses = []
    dis_losses = []
    number_of_batches = int(X_train.shape[0] / batch_size)
    for index in range(number_of_batches):
        print("Batch:{}".format(index+1))
        z_noise = np.random.normal(0, 1, size=(batch_size, z_dim))
        image_batch = X_train[index * batch_size:(index + 1) * batch_size]
        embedding_batch = embeddings_train[index * batch_size:(index + 1) * batch_size]
        image_batch = (image_batch - 127.5) / 127.5
        fake_images, _ = stage1_gen.predict([embedding_batch, z_noise], verbose=3)
        compressed_embedding = embedding_compressor_model.predict_on_batch(embedding_batch)
        compressed_embedding = np.reshape(compressed_embedding, (-1, 1, 1, condition_dim))
        compressed_embedding = np.tile(compressed_embedding, (1, 4, 4, 1))
        dis_loss_real = stage1_dis.train_on_batch([image_batch, compressed_embedding],
                                                  np.reshape(real_labels, (batch_size, 1)))
        dis_loss_fake = stage1_dis.train_on_batch([fake_images, compressed_embedding],
                                                  np.reshape(fake_labels, (batch_size, 1)))
        dis_loss_wrong = stage1_dis.train_on_batch([image_batch[:(batch_size - 1)], compressed_embedding[1:]],
                                                    np.reshape(fake_labels[1:], (batch_size-1, 1)))

        d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake))
        print("d_loss_real:{}".format(dis_loss_real))
        print("d_loss_fake:{}".format(dis_loss_fake))
        print("d_loss_wrong:{}".format(dis_loss_wrong))
        print("d_loss:{}".format(d_loss))
        g_loss = adversarial_model.train_on_batch([embedding_batch, z_noise, compressed_embedding],[K.ones((batch_size, 1)) * 0.9, K.ones((batch_size, 256)) * 0.9])
        print("g_loss:{}".format(g_loss))
        dis_losses.append(d_loss)
        gen_losses.append(g_loss)
    if epoch % 2 == 0:
        z_noise2 = np.random.normal(0, 1, size=(batch_size, z_dim))
        embedding_batch = embeddings_test[0:batch_size]
        fake_images, _ = stage1_gen.predict_on_batch([embedding_batch, z_noise2])
        for i, img in enumerate(fake_images[:10]):
            save_rgb_img(img, "results/gen_{}_{}.png".format(epoch, i))
stage1_gen.save_weights("stage1_gen.h5")
stage1_dis.save_weights("stage1_dis.h5")
